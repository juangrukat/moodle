{
  //============================================================
  // Moodle GIFT Style Guide (v1.0 – July 2025)
  // Purpose: Give an LLM an explicit reference for generating
  // Moodle‑compliant questions in GIFT format.
  //============================================================

  "meta": {
    "encoding": "UTF‑8",                // Always save files in UTF‑8
    "blank_line_between_questions": true,
    "title_required": true,              // Each question must have ::Title::
    "teacher_comment_required": true,    // Every ~wrong answer needs #comment explaining why
    "tags_per_question": 10,             // Exactly ten tags per question
    "escape_rule": "Use a backslash (\\) before ~ = # { } : when they appear as normal text."
  },

  //‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑
  // Unified Tag Taxonomy – choose **exactly 10** tags for every
  // generated question to describe the information type tested.
  //‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑
  "tags": [
    "fact_recall", "definition", "terminology", "concept_check", "historical_date",
    "classification", "process_step", "example_identification", "application",
    "misconception_check", "calculation", "estimation", "relationship", "cause_effect",
    "sequence", "comparison", "analysis", "synthesis", "evaluation", "creative"
  ],

  //‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑
  // Question Type Templates
  // Each object below contains:
  //   • description – plain‑language overview
  //   • template    – skeletal GIFT snippet with placeholders
  //   • parameters  – configurable elements expected from the LLM
  //   • recommended_tags – 10 tag suggestions suited to this type
  //‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑‑
  "question_types": {

    "multiple_choice_single": {
      "description": "One correct answer, radio‑button style.",
      "template": "::${title}:: ${question_text} {\n =${correct_answer} #${correct_feedback}\n ~${wrong_answer_1} #${feedback_1}\n ~${wrong_answer_2} #${feedback_2}\n ...\n}",
      "parameters": {
        "title": "String – 3‑12 words summarising the ask.",
        "question_text": "Prompt. May start with [html]|[markdown]|[plain]|[moodle].",
        "answers[]": {
          "text": "String",
          "is_correct": "Boolean (exactly one true)",
          "weight": "Optional %n% (numeric)",
          "feedback": "String – teacher explanation (required for wrong answers, optional for correct)."
        },
        "shuffle": "Boolean – if true, Moodle shuffles answers.",
        "default_grade": "Number – points awarded for full credit."
      },
      "recommended_tags": [
        "fact_recall", "definition", "terminology", "concept_check", "historical_date",
        "classification", "process_step", "example_identification", "misconception_check", "basic_math"
      ]
    },

    "multiple_choice_multiple": {
      "description": "Checkbox question with two or more partially weighted correct answers.",
      "template": "::${title}:: ${question_text} {\n ~%${neg_weight}%${distractor} #${feedback_d}\n ~%${pos_weight_1}%${correct_part_1} #${feedback_c1}\n ...\n}",
      "parameters": {
        "answers[]": {
          "text": "String",
          "weight": "Percent – positive for correct, negative for penalties.",
          "feedback": "String – teacher explanation."
        },
        "total_positive_weight": "≤100 – avoid automatic full marks via select‑all.",
        "min_negative_weight": "Use at least ‑50% for clear distractors."
      },
      "recommended_tags": [
        "analysis", "comparison", "classification", "application", "concept_check",
        "misconception_check", "relationship", "process_step", "sequence", "cause_effect"
      ]
    },

    "true_false": {
      "description": "Binary TRUE/FALSE statement.",
      "template": "::${title}:: ${statement} {${T_or_F}}\n#${feedback_wrong}\n#${feedback_right}",
      "parameters": {
        "statement": "Proposition being evaluated.",
        "correct_value": "T | F (or TRUE | FALSE)",
        "feedback_wrong": "Comment displayed when learner is incorrect.",
        "feedback_right": "Comment displayed when learner is correct (optional but recommended)."
      },
      "recommended_tags": [
        "fact_recall", "concept_check", "misconception_check", "definition", "relationship",
        "historical_date", "cause_effect", "basic_math", "terminology", "sequence"
      ]
    },

    "short_answer": {
      "description": "Learner types a short text answer; multiple spellings allowed.",
      "template": "::${title}:: ${question_text} {=${answer1} #${fb1} =${answer2} #${fb2} ...}",
      "parameters": {
        "answers[]": {
          "text": "Accepted answer variant.",
          "weight": "Optional %n% for partial credit.",
          "feedback": "String – explanation when this variant is used."
        },
        "usecase": "0 (case‑insensitive) | 1 (case‑sensitive)"
      },
      "recommended_tags": [
        "definition", "terminology", "fact_recall", "historical_date", "process_step",
        "classification", "concept_check", "example_identification", "calculation", "sequence"
      ]
    },

    "matching": {
      "description": "Learner pairs prompts with matches.",
      "template": "::${title}:: ${question_text} {\n =${left_1} -> ${right_1}\n =${left_2} -> ${right_2}\n =${left_3} -> ${right_3}\n}",
      "parameters": {
        "pairs[]": { "left": "String", "right": "String" },
        "min_pairs": 3
      },
      "recommended_tags": [
        "classification", "terminology", "definition", "relationship", "sequence",
        "cause_effect", "example_identification", "process_step", "comparison", "fact_recall"
      ]
    },

    "missing_word": {
      "description": "Fill‑in‑the‑blank embedded answers.",
      "template": "::${title}:: ${sentence_with_{~distractor =correct}...}",
      "parameters": {
        "sentence": "Text containing inline answer set.",
        "answers_per_gap": "≥2 (one =correct, ≥1 ~wrong)",
        "feedback": "Inline #feedback for each option."
      },
      "recommended_tags": [
        "terminology", "definition", "fact_recall", "historical_date", "process_step",
        "sequence", "basic_math", "example_identification", "concept_check", "classification"
      ]
    },

    "numerical": {
      "description": "Numeric input with tolerance or ranges.",
      "template": "::${title}:: ${question_text} {#${answer}:${tolerance}}",
      "parameters": {
        "answer": "Number or min..max span.",
        "tolerance": "Accepted ± range (e.g., 0.5).",
        "partial_credit_ranges": "Use =%n%value:tolerance syntax for graded bands.",
        "feedback_each_range": "#comment follows each range."
      },
      "recommended_tags": [
        "calculation", "estimation", "basic_math", "fact_recall", "historical_date",
        "process_step", "relationship", "concept_check", "example_identification", "misconception_check"
      ]
    },

    "essay": {
      "description": "Open response graded manually.",
      "template": "::${title}:: ${prompt} {}",
      "parameters": {
        "prompt": "Question or task.",
        "grader_info": "Optional directions to human grader.",
        "expected_word_count": "Optional range."
      },
      "recommended_tags": [
        "analysis", "synthesis", "evaluation", "creative", "application",
        "cause_effect", "relationship", "comparison", "historical_date", "concept_check"
      ]
    },

    "description": {
      "description": "Non‑interactive text shown to learners.",
      "template": "::${title}:: ${content}",
      "parameters": {
        "content": "Informational text (no answer block)."
      },
      "recommended_tags": [
        "example_identification", "definition", "process_step", "sequence", "concept_check",
        "relationship", "historical_date", "classification", "fact_recall", "cause_effect"
      ]
    }
  }
}
